{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2216dd1-4fc8-42eb-9094-23c8f96bbba1",
   "metadata": {},
   "source": [
    "# Use PyTorch to Predict Hotel Cancellations\n",
    "\n",
    "- [View Solution Notebook](./solutions.html)\n",
    "- [View Project Page](https://www.codecademy.com/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b298ad9f-91f0-4ff2-b666-45aa85b477d4",
   "metadata": {},
   "source": [
    "**Setup - Import libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9df68894-cfd7-450e-a72d-bd1f99e3e96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#modules are first imported \n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0041b071-2761-49db-a716-66ffaddf5cac",
   "metadata": {},
   "source": [
    "## Task Group 1 - Import and Inspect\n",
    "\n",
    "The file `'datasets/resort_hotel_bookings.csv'` contains a subset of a [real-world dataset](https://www.kaggle.com/datasets/jessemostipak/hotel-booking-demand) containing reservation and cancellation data for a \n",
    "resort hotel. \n",
    "\n",
    "Your goal in this project is build and train a neural network to predict if a customer will cancel their hotel booking reservation based on data including the booking dates, average daily cost, number of adults/children/babies, duration of stay, and so forth."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a125c1e-9b3e-484e-90e9-89d95ebddb08",
   "metadata": {},
   "source": [
    "### Task 1\n",
    "\n",
    "Begin by importing the CSV file to a pandas DataFrame named `hotels`.\n",
    "\n",
    "Preview the first five rows using the `.head()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a70147e-a769-4e34-bb58-6ed3ad8f5e36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_canceled</th>\n",
       "      <th>lead_time</th>\n",
       "      <th>arrival_date_year</th>\n",
       "      <th>arrival_date_month</th>\n",
       "      <th>arrival_date_week_number</th>\n",
       "      <th>arrival_date_day_of_month</th>\n",
       "      <th>stays_in_weekend_nights</th>\n",
       "      <th>stays_in_week_nights</th>\n",
       "      <th>adults</th>\n",
       "      <th>children</th>\n",
       "      <th>...</th>\n",
       "      <th>deposit_type</th>\n",
       "      <th>agent</th>\n",
       "      <th>company</th>\n",
       "      <th>days_in_waiting_list</th>\n",
       "      <th>customer_type</th>\n",
       "      <th>adr</th>\n",
       "      <th>required_car_parking_spaces</th>\n",
       "      <th>total_of_special_requests</th>\n",
       "      <th>reservation_status</th>\n",
       "      <th>reservation_status_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>342</td>\n",
       "      <td>2015</td>\n",
       "      <td>July</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>No Deposit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Check-Out</td>\n",
       "      <td>2015-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>737</td>\n",
       "      <td>2015</td>\n",
       "      <td>July</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>No Deposit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Check-Out</td>\n",
       "      <td>2015-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2015</td>\n",
       "      <td>July</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>No Deposit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Check-Out</td>\n",
       "      <td>2015-07-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>2015</td>\n",
       "      <td>July</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>No Deposit</td>\n",
       "      <td>304.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Check-Out</td>\n",
       "      <td>2015-07-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>2015</td>\n",
       "      <td>July</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>No Deposit</td>\n",
       "      <td>240.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Check-Out</td>\n",
       "      <td>2015-07-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_canceled  lead_time  arrival_date_year arrival_date_month  \\\n",
       "0            0        342               2015               July   \n",
       "1            0        737               2015               July   \n",
       "2            0          7               2015               July   \n",
       "3            0         13               2015               July   \n",
       "4            0         14               2015               July   \n",
       "\n",
       "   arrival_date_week_number  arrival_date_day_of_month  \\\n",
       "0                        27                          1   \n",
       "1                        27                          1   \n",
       "2                        27                          1   \n",
       "3                        27                          1   \n",
       "4                        27                          1   \n",
       "\n",
       "   stays_in_weekend_nights  stays_in_week_nights  adults  children  ...  \\\n",
       "0                        0                     0       2       0.0  ...   \n",
       "1                        0                     0       2       0.0  ...   \n",
       "2                        0                     1       1       0.0  ...   \n",
       "3                        0                     1       1       0.0  ...   \n",
       "4                        0                     2       2       0.0  ...   \n",
       "\n",
       "   deposit_type  agent company days_in_waiting_list customer_type   adr  \\\n",
       "0    No Deposit    NaN     NaN                    0     Transient   0.0   \n",
       "1    No Deposit    NaN     NaN                    0     Transient   0.0   \n",
       "2    No Deposit    NaN     NaN                    0     Transient  75.0   \n",
       "3    No Deposit  304.0     NaN                    0     Transient  75.0   \n",
       "4    No Deposit  240.0     NaN                    0     Transient  98.0   \n",
       "\n",
       "   required_car_parking_spaces  total_of_special_requests reservation_status  \\\n",
       "0                            0                          0          Check-Out   \n",
       "1                            0                          0          Check-Out   \n",
       "2                            0                          0          Check-Out   \n",
       "3                            0                          0          Check-Out   \n",
       "4                            0                          1          Check-Out   \n",
       "\n",
       "  reservation_status_date  \n",
       "0              2015-07-01  \n",
       "1              2015-07-01  \n",
       "2              2015-07-02  \n",
       "3              2015-07-02  \n",
       "4              2015-07-03  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    -> we are importing and inspecting the dataset\n",
    "    -> this is from a csv file \n",
    "    -> this contains hotel data\n",
    "    -> we want a network to predict if customers will cancel their bookings or not \n",
    "    -> the data is first imported from a csv file, using the .read_csv method\n",
    "    -> the .head() method is then used to inspect the first 5 rows of this \n",
    "\"\"\"\n",
    "\n",
    "hotels = pd.read_csv(\"datasets/resort_hotel_bookings.csv\")\n",
    "hotels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7425cc3-dd20-4dab-a6a9-539b994dd9b9",
   "metadata": {},
   "source": [
    "<details><summary style=\"display:list-item; font-size:16px; color:blue;\">Here's a quick summary of the columns</summary>\n",
    "\n",
    "- **is_canceled**: Whether the booking was canceled (1) or kept (0)\n",
    "- **lead_time**: Number of days between booking date and arrival date\n",
    "- **arrival_date_year**: Year of arrival date\n",
    "- **arrival_date_month**: Month of arrival date\n",
    "- **arrival_date_week_number**: Week number of arrival date\n",
    "- **arrival_date_day_of_month**: Day of the month of arrival date\n",
    "- **stays_in_weekend_nights**: Number of weekend nights booked (Sat-Sun)\n",
    "- **stay_in_week_nights**: Number of weekday nights booked (Mon-Fri)\n",
    "- **adults**: Number of adults\n",
    "- **children**: Number of children\n",
    "- **babies**: Number of babies\n",
    "- **meal**: Type of meal booked (Undefined/SC, BB, HB, or FB)\n",
    "- **country**: Country of origin of the booker\n",
    "- **market_segment**: Market segment (TA - travel agent, TO - tour operators)\n",
    "- **distribution_channel**: Booking distribution channel (TA - travel agent, TO - tour operators)\n",
    "- **is_repeated_guest**: Is this a repeated guest (1) or not (0)\n",
    "- **previous_cancellations**: The number of previous bookings canceled by the customer\n",
    "- **previous_bookings_not_canceled**: The number of previous bookings not canceled by the customer\n",
    "- **reserved_room_type**: Room type reserved\n",
    "- **assigned_room_type**: Type of assigned room booked\n",
    "- **booking_changes**: Number of booking changes or modifications\n",
    "- **deposit_type**: Type of deposit to guarantee booking (No Deposit, Non Refund, or Refundable)\n",
    "- **agent**: ID of the travel agency that made the booking\n",
    "- **company**: ID of the company that made the booking\n",
    "- **days_in_waiting_list**: Number of days booking was waitlisted before confirmation\n",
    "- **customer_type**: The customer type of booking (Contract, Group, Transient, or Transient-party)\n",
    "- **adr**: The average daily rate (cost) of the booking\n",
    "- **required_car_parking_spaces**: Number of parking spaces requested by the customer\n",
    "- **total_of_special_requests**: Number of special requests by the customer\n",
    "- **reservation_status**: The last reservation status (Canceled, Check-Out, No-Show)\n",
    "- **reservation_status_date**: The date of the last reservation status"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87842e14-50f6-47ec-984a-f30854c859ea",
   "metadata": {},
   "source": [
    "### Task 2\n",
    "\n",
    "Let's explore the data types and whether any data is missing.\n",
    "\n",
    "Use the `.info()` method on the `hotels` DataFrame to inspect the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32ca9cf6-6b13-4e1f-af01-7673cb7305e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40060 entries, 0 to 40059\n",
      "Data columns (total 31 columns):\n",
      " #   Column                          Non-Null Count  Dtype  \n",
      "---  ------                          --------------  -----  \n",
      " 0   is_canceled                     40060 non-null  int64  \n",
      " 1   lead_time                       40060 non-null  int64  \n",
      " 2   arrival_date_year               40060 non-null  int64  \n",
      " 3   arrival_date_month              40060 non-null  object \n",
      " 4   arrival_date_week_number        40060 non-null  int64  \n",
      " 5   arrival_date_day_of_month       40060 non-null  int64  \n",
      " 6   stays_in_weekend_nights         40060 non-null  int64  \n",
      " 7   stays_in_week_nights            40060 non-null  int64  \n",
      " 8   adults                          40060 non-null  int64  \n",
      " 9   children                        40060 non-null  float64\n",
      " 10  babies                          40060 non-null  int64  \n",
      " 11  meal                            40060 non-null  object \n",
      " 12  country                         39596 non-null  object \n",
      " 13  market_segment                  40060 non-null  object \n",
      " 14  distribution_channel            40060 non-null  object \n",
      " 15  is_repeated_guest               40060 non-null  int64  \n",
      " 16  previous_cancellations          40060 non-null  int64  \n",
      " 17  previous_bookings_not_canceled  40060 non-null  int64  \n",
      " 18  reserved_room_type              40060 non-null  object \n",
      " 19  assigned_room_type              40060 non-null  object \n",
      " 20  booking_changes                 40060 non-null  int64  \n",
      " 21  deposit_type                    40060 non-null  object \n",
      " 22  agent                           31851 non-null  float64\n",
      " 23  company                         3108 non-null   float64\n",
      " 24  days_in_waiting_list            40060 non-null  int64  \n",
      " 25  customer_type                   40060 non-null  object \n",
      " 26  adr                             40060 non-null  float64\n",
      " 27  required_car_parking_spaces     40060 non-null  int64  \n",
      " 28  total_of_special_requests       40060 non-null  int64  \n",
      " 29  reservation_status              40060 non-null  object \n",
      " 30  reservation_status_date         40060 non-null  object \n",
      "dtypes: float64(4), int64(16), object(11)\n",
      "memory usage: 9.5+ MB\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    -> data types \n",
    "    -> we are in the process of inspecting the dataset\n",
    "    -> metadata about this is Æ’irst printed, using the .info() method \n",
    "    -> this is executed on the variable which stores the csv data \n",
    "\"\"\"\n",
    "\n",
    "hotels.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1e2275-58f3-4687-8aad-69771ca90a05",
   "metadata": {},
   "source": [
    "<details><summary style=\"display:list-item; font-size:16px; color:blue;\">What do we notice about the dataset under inspection?</summary>\n",
    "\n",
    "There are 31 columns and 40,060 total observations in our dataset. The majority of columns do not have missing values.\n",
    "\n",
    "However, we do notice that: \n",
    "- the `agent` and `company` columns seem to have missing values that need to be addressed\n",
    "- the `country` column has a couple of missing values as well\n",
    "\n",
    "There are a variety of data types represented. To work with a neural network, we'll have to address any non-numeric columns in our data preparation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4094487-42e0-4ab3-9826-abc746d3a3f1",
   "metadata": {},
   "source": [
    "### Task 3\n",
    "\n",
    "Let's now explore the cancellation column we want to predict.\n",
    "\n",
    "Use the `.value_counts()` method on the `is_canceled` column to count the number **and** the percentage of overall cancellations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aec2e47c-24d1-438f-a6fe-dcdc28700cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_canceled\n",
      "0    28938\n",
      "1    11122\n",
      "Name: count, dtype: int64\n",
      "is_canceled\n",
      "0    0.722366\n",
      "1    0.277634\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    -> we are now inspecting the column in the dataset which we want to make predictions about <- the number of customers which made bookings and then cancelled them \n",
    "    -> the .value_counts() method counts the number of entries in a column in a dataset \n",
    "    -> this allows us to count the number \n",
    "\"\"\"\n",
    "\n",
    "# Number of cancellations\n",
    "print(hotels['is_canceled'].value_counts(0))\n",
    "\n",
    "# Percentage of cancellations\n",
    "print(hotels['is_canceled'].value_counts(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20301d48-979f-4c8b-b54d-36986aaed720",
   "metadata": {},
   "source": [
    "<details><summary style=\"display:list-item; font-size:16px; color:blue;\">What do we notice about the number of cancellations?</summary>\n",
    "\n",
    "The number of cancellations is much lower than the number of non-cancellations (27.8% canceled vs 72.2% did not cancel). \n",
    "\n",
    "We'll need to take this imbalance into account when we evaluate our model. For example, a naive model could simply predict every booking will **not be canceled** and achieve a decent accuracy of 72.2%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439532b9-8f05-49b0-95c8-8d95872722a9",
   "metadata": {},
   "source": [
    "### Task 4\n",
    "\n",
    "The `reservation_status` column tells us if the booking was canceled while also telling us if the customer was a no-show.\n",
    "\n",
    "We need to be sure to exclude this column from the training set, otherwise this information will be _leaked_ to our model resulting in inaccurate performance. \n",
    "\n",
    "First, let's take a quick look at the values in this column.\n",
    "\n",
    "Use the `.value_counts()` method on the `reservation_status` column to count the number **and** the percentage of overall cancellations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42306a5e-144f-49f7-acd8-a505bf137522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reservation_status\n",
      "Check-Out    28938\n",
      "Canceled     10831\n",
      "No-Show        291\n",
      "Name: count, dtype: int64\n",
      "reservation_status\n",
      "Check-Out    0.722366\n",
      "Canceled     0.270369\n",
      "No-Show      0.007264\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "\t-> we are getting rid of the data which we don't want \n",
    "\t-> inspecting the data we want to predict and voiding the data we don't \n",
    "\t-> but first importing the dataset in a csv file\n",
    "\"\"\"\n",
    "\n",
    "# Number of cancellations\n",
    "print(hotels['reservation_status'].value_counts(0))\n",
    "\n",
    "# Percentage of cancellations\n",
    "print(hotels['reservation_status'].value_counts(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d835c66-464d-4210-b7cc-7dae55b3bda1",
   "metadata": {},
   "source": [
    "<details><summary style=\"display:list-item; font-size:16px; color:blue;\">What do we notice about the reservation_status column?</summary>\n",
    "\n",
    "The number of no-shows is extremely small and consists of only 291 (or 0.7%) of observations in the dataset.\n",
    "\n",
    "Later on, we'll look at creating a multiclass model to predict no-show in addition to canceled."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69cad566-ae8b-4879-9f78-4023c662626c",
   "metadata": {},
   "source": [
    "### Task 5\n",
    "\n",
    "Before diving into building a model, let's continue to explore the dataset. It's important to understand how different columns interact with cancellations to guide our model structure! \n",
    "\n",
    "For example, cancellations might be higher in the summer months (June - September) and lower in the winter months (November - January).\n",
    "\n",
    "Use the `.groupby()` method to group the data by the `arrival_date_month` column and apply the `.mean()` aggregation function on the `is_canceled` column. This will return the percent of reservations cancelled in each month.\n",
    "\n",
    "Then, use the `.sort_values()` method to sort the percentages from lowest to highest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7017752e-2799-4aa7-816a-dd7574af0c49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "arrival_date_month\n",
       "January      0.148199\n",
       "November     0.189167\n",
       "March        0.228717\n",
       "December     0.238293\n",
       "February     0.256204\n",
       "October      0.275105\n",
       "May          0.287721\n",
       "April        0.293433\n",
       "July         0.314017\n",
       "September    0.323681\n",
       "June         0.330706\n",
       "August       0.334491\n",
       "Name: is_canceled, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\t-> inspecting trends in the data before building the model \n",
    "\t-> the .groupby() method is used for this <- to group data by certain months \n",
    "\t-> then the .mean() method to calculate means here \n",
    "\t-> the structure of the model will depend on these trends \n",
    "\t-> how we define the model architecture depends on this\n",
    "\t-> the .sort_values() method to sort the percentages in ascending order for this\n",
    "\"\"\"\n",
    "\n",
    "cancellations_by_month = hotels.groupby('arrival_date_month')['is_canceled'].mean()\n",
    "cancellations_by_month.sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0b30f9-951f-4867-8db1-829301ffdf67",
   "metadata": {},
   "source": [
    "<details><summary style=\"display:list-item; font-size:16px; color:blue;\">What do we notice about the percentage of cancellations by month?</summary>\n",
    "\n",
    "It looks like our intuition was correct! Winter and spring have the lowest cancellation percentages, while summer and fall have the highest. This information can be very useful for our model!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3aea04a-4f56-43bf-be51-48d042855eb0",
   "metadata": {},
   "source": [
    "It might be useful to do more exploratory data analysis to gain additional insights about hotel cancellations. For example, additional analysis may help you select better features to train the model on and exclude features that might seem irrelevant. But for now, let's move on to cleaning and preparing the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5e5614-bf65-4f8b-850b-2ca02a6830f7",
   "metadata": {},
   "source": [
    "## Task Group 2 - Data Cleaning and Preparation\n",
    "\n",
    "In this section, we'll encode categorical data for use in our neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e7de66-f973-4580-be8d-ce652ae2aeae",
   "metadata": {},
   "source": [
    "### Task 6\n",
    "\n",
    "To get a sense of the categorical data in the dataset, let's start by previewing the first five rows of all columns with `object` datatype.\n",
    "\n",
    "Create a list named `object_columns` containing only the names of the object columns (except for the reservation status columns). Select those columns from `hotels` and preview the first `5` rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f46a21ff-6eda-4575-8119-903e455469c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arrival_date_month</th>\n",
       "      <th>meal</th>\n",
       "      <th>country</th>\n",
       "      <th>market_segment</th>\n",
       "      <th>distribution_channel</th>\n",
       "      <th>reserved_room_type</th>\n",
       "      <th>assigned_room_type</th>\n",
       "      <th>deposit_type</th>\n",
       "      <th>customer_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>July</td>\n",
       "      <td>BB</td>\n",
       "      <td>PRT</td>\n",
       "      <td>Direct</td>\n",
       "      <td>Direct</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>No Deposit</td>\n",
       "      <td>Transient</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>July</td>\n",
       "      <td>BB</td>\n",
       "      <td>PRT</td>\n",
       "      <td>Direct</td>\n",
       "      <td>Direct</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>No Deposit</td>\n",
       "      <td>Transient</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>July</td>\n",
       "      <td>BB</td>\n",
       "      <td>GBR</td>\n",
       "      <td>Direct</td>\n",
       "      <td>Direct</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>No Deposit</td>\n",
       "      <td>Transient</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>July</td>\n",
       "      <td>BB</td>\n",
       "      <td>GBR</td>\n",
       "      <td>Corporate</td>\n",
       "      <td>Corporate</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>No Deposit</td>\n",
       "      <td>Transient</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>July</td>\n",
       "      <td>BB</td>\n",
       "      <td>GBR</td>\n",
       "      <td>Online TA</td>\n",
       "      <td>TA/TO</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>No Deposit</td>\n",
       "      <td>Transient</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  arrival_date_month meal country market_segment distribution_channel  \\\n",
       "0               July   BB     PRT         Direct               Direct   \n",
       "1               July   BB     PRT         Direct               Direct   \n",
       "2               July   BB     GBR         Direct               Direct   \n",
       "3               July   BB     GBR      Corporate            Corporate   \n",
       "4               July   BB     GBR      Online TA                TA/TO   \n",
       "\n",
       "  reserved_room_type assigned_room_type deposit_type customer_type  \n",
       "0                  C                  C   No Deposit     Transient  \n",
       "1                  C                  C   No Deposit     Transient  \n",
       "2                  A                  C   No Deposit     Transient  \n",
       "3                  A                  A   No Deposit     Transient  \n",
       "4                  A                  A   No Deposit     Transient  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\t-> the data is first imported as a csv, then inspected\n",
    "\t-> before we make a model out of the data ,we need to get rid of (or encode) the categorical data\n",
    "\t-> this cell inspects the first 5 columns of the DataSet, using the .head() method for this \n",
    "\t-> we also now have another variable which stores the collumn names of the dataset \n",
    "\"\"\"\n",
    "\n",
    "object_columns = ['arrival_date_month', 'meal', 'country', 'market_segment', 'distribution_channel', 'reserved_room_type', 'assigned_room_type', 'deposit_type', 'customer_type']\n",
    "hotels[object_columns].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba362e67-edfb-4b2a-acfe-3c2be4ebc711",
   "metadata": {},
   "source": [
    "<details><summary style=\"display:list-item; font-size:16px; color:blue;\">Hint: Preview the first five rows subset by the object columns</summary>\n",
    "\n",
    "Here's how we can subset the DataFrame by the object columns and preview the first five rows:\n",
    "\n",
    "```py\n",
    "object_columns = ['arrival_date_month', 'meal', 'country', 'market_segment', 'distribution_channel', 'reserved_room_type', 'assigned_room_type', 'deposit_type', 'customer_type']\n",
    "hotels[object_columns].head()\n",
    "```\n",
    "\n",
    "Additionally, it might be helpful to explore the categorical data in each object column using the `.value_counts()` method.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6642631-3b52-4969-ba5a-da0bc952d070",
   "metadata": {},
   "source": [
    "### Task 7\n",
    "\n",
    "Typically, we don't want to use every column in training. For example, we may want to drop columns with many missing values or columns that are irrelevant to our prediction task.\n",
    "\n",
    "Drop any columns you don't want to use to train a cancellation model (do not remove the target label column). Feel free to open our Hint to review the columns we chose to drop in our solution.\n",
    "\n",
    "Note: We don't want to drop the `reservation_status` column from the dataset quite yet because we'll be using this column to train our multiclass neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1e0daa-91ef-43ae-8b37-a3e545533729",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    -> the first variable in this stores the collumn names in the set which we want to drop\n",
    "    -> the second variable stores the dataset in which these have been dropped \n",
    "\t-> the .drop() method is then used, to get rid of all of the columns in the dataset which we don't want to train the model on \n",
    "\"\"\"\n",
    "\n",
    "drop_columns = ['country', 'agent', 'company', 'reservation_status_date',\n",
    "                'arrival_date_week_number', 'arrival_date_day_of_month', 'arrival_date_year']\n",
    "\n",
    "hotels = hotels.drop(labels=drop_columns, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53b42e7-17d6-4123-8048-7b7922acc582",
   "metadata": {},
   "source": [
    "<details><summary style=\"display:list-item; font-size:16px; color:blue;\">Hint: Drop columns in the dataset not used for training.</summary>\n",
    "\n",
    "Here's a list of potential features to drop. Feel free to experiment on your own by dropping or keeping columns you might believe may contribute to training.\n",
    "\n",
    "```py\n",
    "drop_columns = ['country', 'agent', 'company', 'reservation_status_date',\n",
    "                'arrival_date_week_number', 'arrival_date_day_of_month', 'arrival_date_year']\n",
    "\n",
    "hotels = hotels.drop(labels=drop_columns, axis=1)\n",
    "```\n",
    "\n",
    "Here's why we chose these columns:\n",
    "\n",
    "- `country` - there are many countries that only appear a handful of times in the dataset which may make our model less generalizable and even discriminate against customers based on their country\n",
    "- `agent` - similar to `country`, there are many agents that only appear a handful of times which may make our model less generalizable (and there are many missing values!)\n",
    "- `company` - similar to `agent`, there are many companies that only appear a handful of times which may make our model less generalizable (and there are many missing values!)\n",
    "- `reservation_status_date` - tells us the date of the latest status change of the reservation which shouldn't be helpful and if anything may leak data\n",
    "- `arrival_date_week_number` - tells us the week of the year which may be too specific and prone to overfitting\n",
    "- `arrival_date_day_of_month` - tells us the day of the month which may be too specific and prone to overfitting\n",
    "- `arrival_date_year` - tells us the year of the booking which may not be helpful to predict future years\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b534b1e-fb7e-44f0-abae-fc2bd3c12fba",
   "metadata": {},
   "source": [
    "### Task 8\n",
    "\n",
    "Next, let's encode the `meal` column which tells us which type of meal(s) the customer booked: \n",
    "\n",
    "- `Undefined` and `SC` correspond to no meal packages\n",
    "- `BB` corresponds to breakfast only\n",
    "- `HB` (half board) corresponds to breakfast + lunch or dinner\n",
    "- `FB` (full board) corresponds to breakfast, lunch, and dinner.\n",
    "\n",
    "Label encode the `meal` column with a meaningful order (# of meals booked) using the following scheme:\n",
    "\n",
    "- `Undefined` and `SC` to `0`\n",
    "- `BB` to `1`\n",
    "- `HB` to `2`\n",
    "- `FB` to `3` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ece4bef-9603-43dc-ade9-f09be6ecf44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\t-> we have imported the dataset, inspected it and dropped the columns which we don't want\n",
    "\t-> now we are converting the categorical (word) data into numerical data in one of the columns \n",
    "\t-> this is done using the .replace() method, which looks like a dictionary \n",
    "\"\"\"\n",
    "\n",
    "hotels['meal'] = hotels['meal'].replace({'Undefined':0, 'SC':0, 'BB':1, 'HB':2, 'FB':3})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb822fb5-a608-45d7-a916-e18da55c7040",
   "metadata": {},
   "source": [
    "### Task 9\n",
    "\n",
    "Let's prepare the rest of the categorical columns using one-hot encoding. \n",
    "\n",
    "Create a list named `one_hot_columns` containing the list of categorical column names (all the remaining categorical columns) to be one-hot encoded using the `pd.get_dummies()` method.\n",
    "\n",
    "Preview the cleaned `hotels` DataFrame using the `.head()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1868c916-5d34-4906-b530-909ba64da1c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_canceled</th>\n",
       "      <th>lead_time</th>\n",
       "      <th>stays_in_weekend_nights</th>\n",
       "      <th>stays_in_week_nights</th>\n",
       "      <th>adults</th>\n",
       "      <th>children</th>\n",
       "      <th>babies</th>\n",
       "      <th>meal</th>\n",
       "      <th>is_repeated_guest</th>\n",
       "      <th>previous_cancellations</th>\n",
       "      <th>...</th>\n",
       "      <th>customer_type_Contract</th>\n",
       "      <th>customer_type_Group</th>\n",
       "      <th>customer_type_Transient</th>\n",
       "      <th>customer_type_Transient-Party</th>\n",
       "      <th>market_segment_Complementary</th>\n",
       "      <th>market_segment_Corporate</th>\n",
       "      <th>market_segment_Direct</th>\n",
       "      <th>market_segment_Groups</th>\n",
       "      <th>market_segment_Offline TA/TO</th>\n",
       "      <th>market_segment_Online TA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>342</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>737</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_canceled  lead_time  stays_in_weekend_nights  stays_in_week_nights  \\\n",
       "0            0        342                        0                     0   \n",
       "1            0        737                        0                     0   \n",
       "2            0          7                        0                     1   \n",
       "3            0         13                        0                     1   \n",
       "4            0         14                        0                     2   \n",
       "\n",
       "   adults  children  babies  meal  is_repeated_guest  previous_cancellations  \\\n",
       "0       2       0.0       0     1                  0                       0   \n",
       "1       2       0.0       0     1                  0                       0   \n",
       "2       1       0.0       0     1                  0                       0   \n",
       "3       1       0.0       0     1                  0                       0   \n",
       "4       2       0.0       0     1                  0                       0   \n",
       "\n",
       "   ...  customer_type_Contract  customer_type_Group  customer_type_Transient  \\\n",
       "0  ...                       0                    0                        1   \n",
       "1  ...                       0                    0                        1   \n",
       "2  ...                       0                    0                        1   \n",
       "3  ...                       0                    0                        1   \n",
       "4  ...                       0                    0                        1   \n",
       "\n",
       "   customer_type_Transient-Party  market_segment_Complementary  \\\n",
       "0                              0                             0   \n",
       "1                              0                             0   \n",
       "2                              0                             0   \n",
       "3                              0                             0   \n",
       "4                              0                             0   \n",
       "\n",
       "   market_segment_Corporate market_segment_Direct  market_segment_Groups  \\\n",
       "0                         0                     1                      0   \n",
       "1                         0                     1                      0   \n",
       "2                         0                     1                      0   \n",
       "3                         1                     0                      0   \n",
       "4                         0                     0                      0   \n",
       "\n",
       "   market_segment_Offline TA/TO  market_segment_Online TA  \n",
       "0                             0                         0  \n",
       "1                             0                         0  \n",
       "2                             0                         0  \n",
       "3                             0                         0  \n",
       "4                             0                         1  \n",
       "\n",
       "[5 rows x 67 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\t-> you can't train a neural network on data which involves words\n",
    "\t-> we are in the process of converting categorical data into numerical data\n",
    "\t-> we are now doing this with the rest of the columns in the set which contain this, using one-hot encoding \n",
    "\t-> the first variable in this stores the names of the columns in the set which we want to convert to numbers (encode)\n",
    "\t-> the .get_dummies() method is then used, to convert the categorical data from these columns in the set to numerical data\n",
    "\t-> we can see that this change has worked, by printing the first 5 columns in the dataset using the .head() method \n",
    "\"\"\"\n",
    "\n",
    "one_hot_columns = ['arrival_date_month', 'distribution_channel', 'reserved_room_type', 'assigned_room_type', 'deposit_type', 'customer_type', 'market_segment']\n",
    "\n",
    "hotels = pd.get_dummies(hotels, columns=one_hot_columns, dtype=int)\n",
    "\n",
    "hotels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f02889-5689-4693-84b1-c8eddeb46a71",
   "metadata": {},
   "source": [
    "Perfect! It looks like we've handled all of the categorical variables and prepared the DataFrame for training.\n",
    "\n",
    "Note that the cleaned DataFrame now has 67 columns due to the additional columns created using one-hot encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e9ce60-59ca-4170-9182-1bec8451bab9",
   "metadata": {},
   "source": [
    "## Task Group 3 - Create Training and Testing Sets\n",
    "\n",
    "Next, let's convert our dataset into PyTorch tensors and split them into training and testing sets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6033851d-df90-4c0b-ab04-40933f77129d",
   "metadata": {},
   "source": [
    "### Task 10\n",
    "\n",
    "Let's import the necessary PyTorch libraries and modules. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9789d74-14b4-42c0-a1e7-d9df7ba5c235",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\t-> the dataset was imported, inspected and cleaned\n",
    "\t-> converting the categorical data into numerical data from this now adds in extra columns, so that we have 67 in total \n",
    "\t-> once we have the data, now we want to convert it into PyTorch tensors - for training \n",
    "\t-> we want there to be four of these, half of which are x and half of which are y\n",
    "\t-> half are also for testing and half are also for training, although this isn't necessarily done in a 50/50 split \n",
    "\t-> the first step to doing this is to import additional modules \n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7312231b-c500-4022-b172-e4e67662ce5d",
   "metadata": {},
   "source": [
    "### Task 11\n",
    "\n",
    "We need to start by separating our training features from the target labels.\n",
    "\\\n",
    "Create a list named `train_features` that contains all of the feature names (column names excluding the target variables `is_canceled` and `reservation_status`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f568ef4b-8287-4fbb-ad5a-16575da41df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\t-> now, we have an entire cleaned dataset\n",
    "\t-> we are splitting this into target labels and training features\n",
    "\t-> target labels \n",
    "\t\t-> target, meaning something we want to predict (the target of the model)\n",
    "\t\t-> labels <- meaning, a parameter which we want to predict\n",
    "\t\t\t-> this parameter isn't a part of the model \n",
    "\t\t\t-> it's an output (a label which we want to predict)\n",
    "\t\t-> these are also known as target columns \n",
    "\t\t\t-> columns which contain data we want to use to make predictions with \n",
    "\n",
    "\t-> training features\n",
    "\t\t-> features in the dataset <- there are multiple columns (factors that will go into making the prediction)\n",
    "\t\t-> training <- to train the model on \n",
    "\n",
    "\t-> we are taking the cleaned dataset, and removing the data which we want the model to predict\n",
    "\t-> the first variable stores the names of the columns which store this data\n",
    "\t-> the second variable removes this from the cleaned set, by using a list comprehension \n",
    "\"\"\"\n",
    "\n",
    "# Remove target columns\n",
    "remove_cols = ['is_canceled', 'reservation_status']\n",
    "\n",
    "# Select training features\n",
    "train_features = [x for x in hotels.columns if x not in remove_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28f6865",
   "metadata": {},
   "source": [
    "<details><summary style=\"display:list-item; font-size:16px; color:blue;\">Hint: Select training features.</summary>\n",
    "\n",
    "```py\n",
    "# Remove target columns\n",
    "remove_cols = ['is_canceled', 'reservation_status']\n",
    "\n",
    "# Select training features\n",
    "train_features = [x for x in hotels.columns if x not in remove_cols]\n",
    "```\n",
    " \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24724a16-795e-4654-9937-ecb3bd173594",
   "metadata": {},
   "source": [
    "### Task 12\n",
    "\n",
    "Using the list of training features in `train_features`, create `X` and `y` tensors:\n",
    "\n",
    "- `X` contains the data values from the `train_features` columns\n",
    "- `y` contains the binary labels in the `is_canceled` column in `hotels`\n",
    "\n",
    "Both `X` and `y` should have the float datatype.\n",
    "\n",
    "Be sure to set the correct view of `y` using `.view(-1,1)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9075979f-c19b-4586-bd71-15ea866d5e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\t-> the data is first imported and inspected\n",
    "\t-> the columns from this are then dropped which we won't use\n",
    "\t-> the categorical data in this is then converted into numerical data\n",
    "\t-> this is then separated into training and testing data \n",
    "\t-> then we look at the training dataset only, and split this into x and y\n",
    "\t-> these are training features and test labels \n",
    "\t-> these labels are created using the PyTorch .tensor() method \n",
    "\"\"\"\n",
    "\n",
    "X = torch.tensor(hotels[train_features].values, dtype=torch.float)\n",
    "y = torch.tensor(hotels['is_canceled'].values, dtype=torch.float).view(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a9c018",
   "metadata": {},
   "source": [
    "<details><summary style=\"display:list-item; font-size:16px; color:blue;\">Hint: Create X and y tensors.</summary>\n",
    "\n",
    "When creating the tensors, be sure to extract the data values in the specified columns using `.values` as floats:\n",
    "    \n",
    "```py\n",
    "X = torch.tensor(hotels[train_features].values, dtype=torch.float)\n",
    "y = torch.tensor(hotels['is_canceled'].values, dtype=torch.float).view(-1,1)\n",
    "```\n",
    " \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf85c1dd-70b3-4c61-902d-1be92daeb39f",
   "metadata": {},
   "source": [
    "### Task 13\n",
    "\n",
    "Let's now split our data contained in `X` and `y` into training and testing sets.\n",
    "\n",
    "Import the `train_test_split` module from Scikit-learn's `sklearn.model_selection` library.\n",
    "\n",
    "Split `X` and `y` using the following scheme:\n",
    "- Use 80% of the data for the training set `X_train` and `y_train`\n",
    "- Use 20% of the data for the testing set `X_test` and `y_test`\n",
    "- Set the random state to `42` to match our solution\n",
    "\n",
    "Print out the shape of `X_train` and `X_test` to see how many observations and columns are in the training and testing sets.\n",
    "\n",
    "How many training features does our training set `X_train` have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f1975f61-365d-4fb9-9106-e8af73181d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Shape: torch.Size([32048, 65])\n",
      "Testing Shape: torch.Size([8012, 65])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "\t-> we are splitting all of the data into test and training sets \n",
    "\t-> it is converted first into x and y, and then split into testing and training sets\n",
    "\t-> modules are first imported\n",
    "\t-> this is an 80/20 split, created with the train_test_split() method\n",
    "\t-> the .shape method is then used to print the shapes of these \n",
    "\"\"\" \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    train_size=0.80,\n",
    "                                                    test_size=0.20,\n",
    "                                                    random_state=42) \n",
    "\n",
    "print(\"Training Shape:\", X_train.shape)\n",
    "print(\"Testing Shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c691550-b23d-4edd-8894-d429ff878ac7",
   "metadata": {},
   "source": [
    "<details><summary style=\"display:list-item; font-size:16px; color:blue;\">Hint: Split the dataset into training and testing splits.</summary>\n",
    "    \n",
    "```py\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    train_size=0.80,\n",
    "                                                    test_size=0.20,\n",
    "                                                    random_state=42) \n",
    "print(\"Training Shape:\", X_train.shape)\n",
    "print(\"Testing Shape:\", X_test.shape)\n",
    "```\n",
    "It looks like our data was successfully split into 80% training and 20% testing sets. \n",
    "\n",
    "Importantly, we see that the number of columns is `65` which corresponds to the number of input nodes (or features) needed in the input layer of our neural network!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f19d0e5-2ba5-488b-9af0-3e5d33e06d29",
   "metadata": {},
   "source": [
    "## Task Group 4 - Train a Neural Network for Binary Classification\n",
    "\n",
    "Let's now create a neural network for binary classification to predict hotel cancellations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c72e761-e422-4893-ac6c-37693886f344",
   "metadata": {},
   "source": [
    "### Task 14\n",
    "\n",
    "Set a random seed to `42` using `torch.manual_seed(42)`.\n",
    "\n",
    "Build the neural network architecture using `nn.Sequential` with the following:\n",
    "- input layer with `65` nodes (equal to the number of training features)\n",
    "- first hidden layer with `36` nodes and a ReLU activation\n",
    "- second hidden layer with `18` nodes and a ReLU activation\n",
    "- output layer with `1` node and a Sigmoid activation\n",
    "\n",
    "Save the network to the variable `model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be281de6-8e20-4e8b-a88b-4259db34dccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\t-> a random seed is first created with the .manual_seed() method\n",
    "\t-> before we train a neural network on the data, we need to initialise its architecture\n",
    "\t-> this is done with the .Sequential() method \n",
    "\t-> each of the different arguments in this method represent a new layer in the neural network \n",
    "\t-> ReLu and Sigmoids are activations \n",
    "\t-> the .Linear() layers are hidden layers in the model \n",
    "\"\"\" \n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(65, 36),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(36, 18),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(18, 1),\n",
    "    nn.Sigmoid()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5399e8f4-213f-43eb-894c-aef2b030c900",
   "metadata": {},
   "source": [
    "### Task 15\n",
    "\n",
    "Next, let's define the loss function and optimizer used for training:\n",
    "- set the **binary cross-entropy** loss function to the variable `loss`\n",
    "- set the **Adam** optimizer to the variable `optimizer` with a learning rate of `0.005`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "03ca9cbf-b5e2-423a-88b0-98c1eb51f492",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\t-> we have the data which has been imported, cleaned and split into four PyTorch tensors \n",
    "\t-> the architecture of the model has also been initialised \n",
    "\t-> now we are defining a loss function and optimiser to train the model on this data  \n",
    "\t-> the loss function \n",
    "\t\t-> BCE <- binary cross-entropy \n",
    "\t\t-> this is initialised with the .BCELoss() method \n",
    "\t->  the optimiser function \n",
    "\t\t-> this is the Adam optimiser and has a learning rate\n",
    "\t\t-> this is set with the .Adam() method\n",
    "\"\"\"\n",
    "\n",
    "loss = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.005)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b596b59-7ae9-4dcd-9f71-11bf324be1f8",
   "metadata": {},
   "source": [
    "### Task 16\n",
    "\n",
    "Let's build the training loop to train our neural network.\n",
    "\n",
    "Train the neural network for `1000` epochs.\n",
    "\n",
    "Keep track of the training performance by printing out the binary cross-entropy loss and accuracy score every `100` epochs.\n",
    "\n",
    "Before calculating accuracy, convert the model's predicted probabilities to binary labels (as integers) using `0.5` as the threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428aeaf3-6952-4050-9a5c-e4f9e6ff794c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], BCELoss: 0.3975, Accuracy: 0.8224\n",
      "Epoch [200/1000], BCELoss: 0.3625, Accuracy: 0.8297\n",
      "Epoch [300/1000], BCELoss: 0.3537, Accuracy: 0.8347\n",
      "Epoch [400/1000], BCELoss: 0.3442, Accuracy: 0.8377\n",
      "Epoch [500/1000], BCELoss: 0.3399, Accuracy: 0.8395\n",
      "Epoch [600/1000], BCELoss: 0.3339, Accuracy: 0.8409\n",
      "Epoch [700/1000], BCELoss: 0.3353, Accuracy: 0.8426\n",
      "Epoch [800/1000], BCELoss: 0.3315, Accuracy: 0.8414\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "\t->  we are training the model on the (training) dataset 1,000 times \n",
    "\t\t-> this is done with a for loop \n",
    "\t-> an epoch is one time the model is trained on this data\n",
    "\t-> we have the data and the model architecture \n",
    "\t-> every 100 epochs, the binary cross-entropy loss and accuracy scores are printed \n",
    "\t\t-> the model's predicted probabilities are converted to binary labels (as integers) during this process \n",
    "\t\t-> modules are first imported for this \n",
    "\t\t-> we then iterate through training epochs, for each one \n",
    "\t\t\t-> the model() method is used to make predictions based on the dataset, which are stored in `predictions`\n",
    "\t\t\t-> the loss from these predictions is calculated, using the loss() method and this is optimised \n",
    "\t\t-> for every 100 epochs \n",
    "\t\t\t-> the accuracy score of the predictions is returned, using the accuracy_score() method \n",
    "\t\t\t-> the output of this is then returned, by using an f string literal\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):\n",
    "    predictions = model(X_train)\n",
    "    BCELoss = loss(predictions, y_train)\n",
    "    BCELoss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        predicted_labels = (predictions >= 0.5).int()\n",
    "        accuracy = accuracy_score(y_train, predicted_labels)\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], BCELoss: {BCELoss.item():.4f}, Accuracy: {accuracy.item():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f27afb4",
   "metadata": {},
   "source": [
    "<details><summary style=\"display:list-item; font-size:16px; color:blue;\">Hint: Keep track of the training loss and accuracy.</summary>\n",
    "\n",
    "    \n",
    "Here's how to print the accuracy and BCE loss every 100 epochs during training:\n",
    "    \n",
    "```py\n",
    "if (epoch + 1) % 100 == 0:\n",
    "        predicted_labels = (predictions >= 0.5).int()\n",
    "        accuracy = accuracy_score(y_train, predicted_labels)\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], BCELoss: {BCELoss.item():.4f}, Accuracy: {accuracy.item():.4f}')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ec35a0-5096-4000-9a7b-f1724a2ef946",
   "metadata": {},
   "source": [
    "### Task 17\n",
    "\n",
    "Let's evaluate the trained neural network on the testing set:\n",
    "\n",
    "1. Set the model to **evaluation mode**\n",
    "2. Turn off gradient calculations\n",
    "3. Generate predicted probabilities on `X_test`. Save the probabilities to the variable `test_predictions`.\n",
    "4. Convert the predicted probabilities to binary labels using `0.5` as the threshold. Save the labels to the variable `test_predicted_labels`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ee1ac3-d63c-4a97-bbbd-2a0a7e502d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\t-> now we have a trained model\n",
    "\t-> we want to see how accurate its predictions are\t\n",
    "\t-> the .eval() method is first used to set the model to evaluation mode \n",
    "\t-> the gradient calculations are then turned off, using the .no_grad() method\n",
    "\t-> predicted probabilities are then generated, using the model() method \n",
    "\t-> these are converted to integers, using the .int() method <- binary labels \n",
    "\"\"\"\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_predictions = model(X_test)\n",
    "    test_predicted_labels = (test_predictions >= 0.5).int()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f37de0-6e5c-4716-ad10-37ced7a86621",
   "metadata": {},
   "source": [
    "### Task 18\n",
    "\n",
    "Recall that the number of cancellations is much lower than the number of non-cancellations (27.8% canceled vs 72.2% did not cancel). \n",
    "\n",
    "To evaluate our neural network effectively, compute the accuracy, precision, recall, and F1 scores using the `sklearn.metrics` module:\n",
    "\n",
    "- use the `accuracy_score` function to compute the overall accuracy\n",
    "- use the `classification_report` function to compute the precision, recall, and F1 scores\n",
    "\n",
    "Print out the accuracy and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434e5601-8cee-430a-b47b-95ce604c50b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\t-> more people cancel than don't \n",
    "\t-> calculating the performance of the model \n",
    "\t\t-> we want to calculate the accuracy, precision, recall, and F1 scores of the model \n",
    "\t\t-> the classification_report function is used for this and then the accuracy and classification reports from it are printed \n",
    "\t-> this involves first importing modules \n",
    "\t-> the accuracy_score method is used to return the accuracy score for this, to 4 significant figures using an f string literal \n",
    "\t\t-> this is repeated to generate the classification report, with the classification_report method\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "test_accuracy = accuracy_score(y_test, test_predicted_labels)\n",
    "print(f'Accuracy: {test_accuracy.item():.4f}')\n",
    "\n",
    "report = classification_report(y_test, test_predicted_labels)\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7e573f-daa9-4918-9228-36e2e06ca16d",
   "metadata": {},
   "source": [
    "Overall, the model seems to perform reasonably well at predicting hotel cancellations!\n",
    "\n",
    "The model has an overall accuracy of 83.7%, indicating that 83.7% of our model's predictions are correct.\n",
    "The precision score tells us that when our model predicts a cancellation, it is correct ~72% of the time.\n",
    "The recall score tells us that our model captures about 68% of the actual cancellations in our data. \n",
    "\n",
    "In future research, we could improve the model by performing a more in-depth analysis of the features and doing a more robust feature selection process (like gathering more features or dropping less useful features). \n",
    "\n",
    "Furthermore, we could modify the neural network architecture by changing the number of nodes across the hidden layers, trying out different activation functions and optimizers, adding more hidden layers, or training on additional epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef7b3ad-9e0d-4ae3-8de8-e20d29c82420",
   "metadata": {},
   "source": [
    "## Task Group 5 - Train a Neural Network for Multiclass Classification\n",
    "\n",
    "Let's now extend our binary classification task to multiclass by attempting to also predict customers who **no-showed** within the `reservation_status` column.\n",
    "\n",
    "If a hotel can accurately predict no-shows, they can reach out ahead of time to customers who are at high risk of not-showing to their reservation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56d798e-d97c-400f-b761-54a02b27c6ad",
   "metadata": {},
   "source": [
    "### Task 19\n",
    "\n",
    "First, let's label encode the three categories in the `reservation_status` column:\n",
    "- **Check-Out** to `2`\n",
    "- **Canceled** to `1`\n",
    "- **No-Show** to `0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af57a73b-b3df-4574-a376-1ba9fddfcf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\t-> we can then analyse the model's accuracy score from this\n",
    "\t-> there are multiple ways which this model can be improved (see above)\n",
    "\t-> extending this to a multiclass classification model \n",
    "\t-> we want to make more predictions, by adding a third category  \n",
    "\t->  this means converting the categorical data into numerical data again, by using the .replace() method \n",
    "\"\"\"\n",
    "\n",
    "hotels['reservation_status'] = hotels['reservation_status'].replace({'Check-Out':2, 'Canceled':1, 'No-Show':0})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776ce78d-5f2c-4fa0-b513-50c79d60e143",
   "metadata": {},
   "source": [
    "### Task 20\n",
    "\n",
    "Using the same list of training features in `train_features`, create the `X` and `y` tensors where:\n",
    "\n",
    "- `X` contains the data values from the `train_features` columns\n",
    "- `y` contains the multiclass data values in the `reservation_status` column\n",
    "\n",
    "Make sure that `y` uses the `long` datatype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095aba89-a375-4581-aafe-5cbaa26e81d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\t-> we are adding another class onto the model \n",
    "\t-> the list of training features for doing this is the same \n",
    "\t-> we repeat the process when making the binary classification model for this \n",
    "\t-> this is again done using the .tensor() method\n",
    "\"\"\"\n",
    "\n",
    "X = torch.tensor(hotels[train_features].values, dtype=torch.float)\n",
    "y = torch.tensor(hotels['reservation_status'].values, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d579ce",
   "metadata": {},
   "source": [
    "<details><summary style=\"display:list-item; font-size:16px; color:blue;\">Hint: Create X and y tensors.</summary>\n",
    "\n",
    "When creating the tensors, be sure to extract the data values in the specified columns using `.values`:\n",
    "    \n",
    "```py\n",
    "X = torch.tensor(hotels[train_features].values, dtype=torch.float)\n",
    "y = torch.tensor(hotels['reservation_status'].values, dtype=torch.long)\n",
    "```\n",
    " \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abbd301-7464-4fbf-abcd-2aaa03478cd9",
   "metadata": {},
   "source": [
    "### Task 21\n",
    "\n",
    "Similar to before, split the `X` and `y` tensors into training and testing splits using the following scheme:\n",
    "- Use 80% of the data for the training set `X_train` and `y_train`\n",
    "- Use 20% of the data for the testing set `X_test` and `y_test`\n",
    "- Set the random state to `42`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9b53ad-8f96-4f25-9253-97020bfcbec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\t-> we are still in the process of adding another class to the model \n",
    "\t-> this involves splitting the x and y tensors into testing and training splits \n",
    "\t-> modules are first imported for this \n",
    "\t-> the train_test_split() method is then used to split the data\n",
    "\t-> this is printed, so we know it has worked\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    train_size=0.8,\n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42) \n",
    "\n",
    "print(\"Training Shape:\", X_train.shape)\n",
    "print(\"Testing Shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b132744",
   "metadata": {},
   "source": [
    "<details><summary style=\"display:list-item; font-size:16px; color:blue;\">Hint: Split the dataset into training and testing splits.</summary>\n",
    "    \n",
    "```py\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    train_size=0.80,\n",
    "                                                    test_size=0.20,\n",
    "                                                    random_state=42) \n",
    "print(\"Training Shape:\", X_train.shape)\n",
    "print(\"Testing Shape:\", X_test.shape)\n",
    "```\n",
    "It looks like our data was successfully split into 80% training and 20% testing sets. \n",
    "\n",
    "Importantly, we see that the number of columns is `65` which corresponds to the number of input nodes (or features) needed in the input layer of our neural network!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746d568e-1964-4885-b911-e5b07a337a84",
   "metadata": {},
   "source": [
    "### Task 22\n",
    "\n",
    "Set a random seed using `torch.manual_seed(42)`.\n",
    "\n",
    "Next, let's construct the multiclass neural network with the following architecture:\n",
    "\n",
    "- input layer with `65` nodes (equal to the number of training features)\n",
    "- first hidden layer with `65` nodes and a ReLU activation\n",
    "- second hidden layer with `36` nodes and a ReLU activation\n",
    "- final output layer with `3` nodes corresponding to each of the categories in `reservation_status`\n",
    "\n",
    "Save the network to the variable `multiclass_model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bcdce8-a0f6-4b42-8e39-14f4514183d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\t-> we are still in the process of converting the this into a multiclass model, rather than a binary one\n",
    "\t-> a random seed is first set using torch.manual_seed(42)\n",
    "\t-> the architecture of the model is then altered\n",
    "\t-> ReLu <- this is an activation layer \n",
    "\t-> the first layer is called the input layer\n",
    "\t-> some of the layers after this are referred to as hidden layers \n",
    "\t-> the final layer is the output layer \n",
    "\"\"\"\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "multiclass_model = nn.Sequential(\n",
    "    nn.Linear(65, 65),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(65, 36),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(36, 3)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da66f270-3ff1-46ae-afb3-bf56f8c48231",
   "metadata": {},
   "source": [
    "### Task 23\n",
    "\n",
    "Next, let's define the loss function and optimizer used for multiclass training:\n",
    "- set the **cross-entropy** loss function for multiclass to the variable `loss`\n",
    "- set the **Adam** optimizer to the variable `optimizer` with a learning rate of `0.01`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054e5888-c5b3-4708-b4d5-a253d503f86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\t-> the loss function for the model is then altered\n",
    "\t-> this is a cross-entropy loss function for multiclass \n",
    "\t-> this is then set to the variable `loss`, using the .CrossEntropyLoss() method\n",
    "\t-> the learning rate of the Adam optimiser is then altered\n",
    "\t\t-> this is done using the optim method \n",
    "\"\"\"\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(multiclass_model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd8d1c8-a815-4371-b905-1696ac3f5faf",
   "metadata": {},
   "source": [
    "### Task 24\n",
    "\n",
    "Let's build the training loop to train our neural network.\n",
    "\n",
    "1. Train the neural network for `500` epochs.\n",
    "2. Keep track of the training performance by printing out the cross-entropy loss and accuracy score every `100` epochs.\n",
    "3. Be sure to convert the output probabilites of the multiclass model to labels using the `torch.argmax()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24d74fd-c2fd-4287-a251-403c5e3ed04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\t-> we are still in the process of converting the binary classification model to a multiclassification model \n",
    "\t-> we are now training the model with the third class being added onto it \n",
    "\t-> this is the same process as before \n",
    "\t\t-> an epoch is one time the model is trained on the data\n",
    "\t\t-> we train the model on the same data, hundreds of times \n",
    "\t\t-> modules for this are first imported\n",
    "\t\t-> and then the model is trained on this, using the multiclass_model() method \n",
    "\t\t-> the loss function for this is then calculated, along with the use of an optimiser\n",
    "\t\t-> the accuracy score for this is printed every 100 epochs \n",
    "\t\t-> the torch.argmax() method converts the outputs of the model to labels from this\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "num_epochs = 500\n",
    "for epoch in range(num_epochs):\n",
    "    predictions = multiclass_model(X_train)\n",
    "    CELoss = loss(predictions, y_train)\n",
    "    CELoss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        predicted_labels = torch.argmax(predictions, dim=1)\n",
    "        accuracy = accuracy_score(y_train, predicted_labels)\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], CELoss: {CELoss.item():.4f}, Accuracy: {accuracy.item():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb78596",
   "metadata": {},
   "source": [
    "<details><summary style=\"display:list-item; font-size:16px; color:blue;\">Hint: Keep track of the multiclass training loss and accuracy.</summary>\n",
    "\n",
    "    \n",
    "Here's how to print the accuracy and BCE loss every 100 epochs during training:\n",
    "    \n",
    "```py\n",
    "if (epoch + 1) % 100 == 0:\n",
    "        predicted_labels = torch.argmax(predictions, dim=1)\n",
    "        accuracy = accuracy_score(y_train, predicted_labels)\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], CELoss: {CELoss.item():.4f}, Accuracy: {accuracy.item():.4f}')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50586271-905d-4229-8a00-611528153b28",
   "metadata": {},
   "source": [
    "### Task 25\n",
    "\n",
    "Let's evaluate the trained neural network on the testing set:\n",
    "\n",
    "1. Set the multiclass model to **evaluation mode**\n",
    "2. Turn off gradient calculations\n",
    "3. Generate predicted probabilities on `X_test`. Save the predicted probabilities to the variable `multiclass_predictions`.\n",
    "4. Select the class with the largest predicted probability using the `torch.argmax()` function. Save the predicted classes to the variable `multiclass_predicted_labels`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92def2d2-e470-40d1-a938-22c6b83f727d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\t-> we have changed the model from binary classification into multiclassification \n",
    "\t-> then trained the model on this \n",
    "\t-> we are now evaluating this on the testing set\n",
    "\t-> this is the same process that was previously used\n",
    "\t-> the .eval() method is first used to set the model to evaluation mode for this\t\n",
    "\t-> the gradient calculations are then turned off, by using the .no_grad() method \n",
    "\t-> the .argmax() function is then used to select the class with the largest probability \n",
    "\"\"\"\n",
    "\n",
    "multiclass_model.eval()\n",
    "with torch.no_grad():\n",
    "    multiclass_predictions = multiclass_model(X_test)\n",
    "    multiclass_predicted_labels = torch.argmax(multiclass_predictions, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9892547-fea8-4d44-988d-2b1aca8b6b24",
   "metadata": {},
   "source": [
    "### Task 26\n",
    "\n",
    "Lastly, let's evaluate the multiclass neural network by calculating the overall accuracy, precision, recall, and F1 scores.\n",
    "\n",
    "Using the `sklearn.metrics` module:\n",
    "- use the `accuracy_score` function to compute and save the overall accuracy to the variable `multiclass_accuracy`\n",
    "- use the `classification_report` function to compute and save the classification metrics for each class to the variable `multiclass_report`\n",
    "\n",
    "Print the overall accuracy and classification report for our multiclass model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d96267-d4ab-49fc-be8e-3175cc7a5b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\t-> we are now calculating the different accuracy scores for the multiclass model, with the additional category added in \n",
    "\t-> modules are first imported for this \n",
    "\t-> the accuracy_score() method is then used to generate an accuracy score for this, and is printed with an f string literal \n",
    "\t\t-> this is repeated with the classification_report() method \n",
    "\t-> we can compare the performance of this model to the binary classification model using these scores / reports \n",
    "\t-> this can be interpreted in the context of data science, to gather more complex insights \n",
    "\t-> it can also tell us where the model is inaccurate <- the percentages of the predictions which are correct \n",
    "\t\t-> from the precision and recall score for this \n",
    "\t\t-> these can be used to make decisions about the dataset\n",
    "\t-> comparing the accuracy of the multiclass and binary classification models \n",
    "\t-> there are multiple ways this can be extended (see below)\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "multiclass_accuracy = accuracy_score(y_test, multiclass_predicted_labels)\n",
    "print(f'Accuracy: {multiclass_accuracy.item():.4f}')\n",
    "\n",
    "multiclass_report = classification_report(y_test, multiclass_predicted_labels)\n",
    "print(\"Classification Report:\\n\", multiclass_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a78ab2c-650c-422f-876f-33e150d8b00c",
   "metadata": {},
   "source": [
    "Our multiclass neural network performs similarly to the binary classification network at predicting cancellations.\n",
    "\n",
    "It has an overall accuracy of 84%, meaning that 84% of all the predictions were correct.\n",
    "The precision in row `1` tells us that when our model predicts a cancellation, it is correct 72% of the time. \n",
    "The recall score in row `1` tells us that our model captures 68% of the actual cancellations in our data.\n",
    "\n",
    "Unfortunately, the model doesn't do the best job of predicting whether or not the customer will no-show. \n",
    "\n",
    "For no-shows (row class `0`), the precision score tells us that when our model predicts a no-show it is correct 86% of the time which is surprising well.\n",
    "However, the low recall score tells us that our model only captures 11% of actual no-shows which is not very good. The lower recall score brings the F1 score down to 27% which indicates a not-so-great balance between precision and recall. This means that the model doesn't predict many no-shows and will most likely not be able to capture most customers who no-show in real-life. \n",
    "\n",
    "If our goal is to be able to reach out to potential no-shows, the low recall score is concerning. However, this all may be due to the low number of no-shows in the dataset: it is much harder for our model to find patterns predicting a no-show without more data. However, unlike the binary model, the multiclass does make an attempt to classify no-shows while still being able to predict cancellations ahead of time with similar performance.\n",
    "\n",
    "So that's the end of our project on predicting hotel cancellations using real-world data! \n",
    "In future research, we could improve the model by performing a more in-depth analysis of the features and doing a more robust feature selection process. Some examples might include collecting weather data at the time of each booking, reservations made on major holidays, economic conditions, or even global pandemics and health concerns.\n",
    "\n",
    "Furthermore, we could also try to improve performance by modifying the neural network architecture like changing the number of nodes across the hidden layers, trying out different activation functions and optimizers, adding more hidden layers, or training on additional epochs, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8f67b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
